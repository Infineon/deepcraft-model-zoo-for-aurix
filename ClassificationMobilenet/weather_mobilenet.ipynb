{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copyright (C) Infineon Technologies AG 2025\n",
    " \n",
    "Copyright (c) 2025, Infineon Technologies AG, or an affiliate of Infineon Technologies AG. All rights reserved.\n",
    "This software, associated documentation and materials (\"Software\") is owned by Infineon Technologies AG or one of its affiliates (\"Infineon\") and is protected by and subject to worldwide patent protection, worldwide copyright laws, and international treaty provisions. Therefore, you may use this Software only as provided in the license agreement accompanying the software package from which you obtained this Software. If no license agreement applies, then any use, reproduction, modification, translation, or compilation of this Software is prohibited without the express written permission of Infineon.\n",
    "\n",
    "Disclaimer: UNLESS OTHERWISE EXPRESSLY AGREED WITH INFINEON, THIS SOFTWARE IS PROVIDED AS-IS, WITH NO WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, ALL WARRANTIES OF NON-INFRINGEMENT OF THIRD-PARTY RIGHTS AND IMPLIED WARRANTIES SUCH AS WARRANTIES OF FITNESS FOR A SPECIFIC USE/PURPOSE OR MERCHANTABILITY. Infineon reserves the right to make changes to the Software without notice. You are responsible for properly designing, programming, and testing the functionality and safety of your intended application of the Software, as well as complying with any legal requirements related to its use. Infineon does not guarantee that the Software will be free from intrusion, data theft or loss, or other breaches (\"Security Breaches\"), and Infineon shall have no liability arising out of any Security Breaches. Unless otherwise explicitly approved by Infineon, the Software may not be used in any application where a failure of the Product or any consequences of the use thereof can reasonably be expected to result in personal injury."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Structure\n",
    "\n",
    "1. **Generation of the Model: MobileNet for Weather Classification**\n",
    "2. **Compiling the Model for AURIX&trade; Microcontrollers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet for Weather Classification\n",
    "\n",
    "In this an example for the classification of different weather conditions using the MobileNetV3-small [1]. The pretrained model will be the foundation applying transfer learning. The model will be tested and then transformed into code which can later be deployed on the AURIX&trade; microcontroller family. \n",
    "\n",
    "### Generation of the Model\n",
    "\n",
    "In this section we will import the MobileNetV3-small. Next, we will replace the classification layer with a new one for two classes. We will train the model for weather classification and then validate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torchsummary import summary\n",
    "import modelling_helper as mh\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from CentralScripts.python_flask_client import CallTools\n",
    "import CentralScripts.helper_functions as cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching data aka setting dataloader. The data which is used is Raindrop Clarify [2]. While this was designed for removing rain drops from images algorithmically, it will here be used for classification only. The data will be downloaded and restructured. From the original dataset only, clear and (rain) drop will be considered. The data will be split into train, validation (val), and test piles. Plotting a random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "path = mh.fetch_sort_data()\n",
    "dataloader, class_names, dataset_sizes = mh.get_dataloader(\n",
    "    os.path.join(path, \"train\"), batch_size, mode=\"train\"\n",
    ")\n",
    "_, input_size = mh.get_input_dataloader(dataloader, is_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the MobileNetV3-small with pretrained weights. It's trained on ImageNet1K dataset [3]. Replacing the classification layer with one for two classes only (rain and clear weather)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "\n",
    "model_original = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT)\n",
    "model = mh.adapt_model(model_original, number_classes=2)\n",
    "summary(model, input_size, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying transfer learning: training the new classification layer only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.classifier[-1].parameters(), lr=0.01, momentum=0.9)\n",
    "mh.train_model(model, dataloader, dataset_sizes, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a random input which can be used for testing on the hardware later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_target, _ = mh.get_input_dataloader(dataloader, is_plot=True)\n",
    "output_target = cs.get_predictions(\"torch\", model, input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the trained model on a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = mh.get_rain_classes()\n",
    "mh.calculate_predictions_and_plot(model, os.path.join(path, \"test\"), classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the trained model on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader, class_names, dataset_sizes = mh.get_dataloader(\n",
    "    os.path.join(path, \"test\"), batch_size, mode=\"test\"\n",
    ")\n",
    "mh.test_model(model, dataloader, dataset_sizes, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model and some input and output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenet_weather\"\n",
    "cs.save_all(model_name, input_target, output_target, model, origin=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model for AURIX&trade; Microcontrollers\n",
    "\n",
    "For compiling, we prepare a Docker container which includes all the required tools for compilation. In this section, we will set up the container and make sure that it's available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.ensure_docker_container()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model for two different targets: AURIX&trade; TC3x and TC4x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder, onnx_model_file = cs.get_output_paths(model_name)\n",
    "\n",
    "for target in [\"TC3\", \"TC4\"]:\n",
    "    tool = CallTools(\n",
    "        folder=model_folder, url=\"http://localhost:8080/convert\", target=target\n",
    "    )\n",
    "    tool.convert_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the run time of the layers using AURIX&trade; TC3x and TC4x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.plot_execution_timing(model_name, is_small_font=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]: Howard, A. et al. (2019). \"Searching for MobileNetV3.\", ICCV.<br>\n",
    "[2]: Jin, Y. et al. (2024). \"Raindrop Clarity: A Dual-Focused Dataset for Day and Night Raindrop Removal\", ECCV, [Link to Github](https://github.com/jinyeying/RaindropClarity?tab=readme-ov-file)<br>\n",
    "[3]: Russakovsky, O. et al. (2015). \"ImageNet Large Scale Visual Recognition Challenge\", IJCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
